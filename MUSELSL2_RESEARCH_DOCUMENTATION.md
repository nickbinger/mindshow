# MuseLSL2 Research Documentation

*Based on analysis of [DominiqueMakowski/MuseLSL2](https://github.com/DominiqueMakowski/MuseLSL2) repository*

## Table of Contents

1. [Repository Overview](#repository-overview)
2. [Key Improvements](#key-improvements)
3. [Installation and Setup](#installation-and-setup)
4. [Core Features](#core-features)
5. [Usage Patterns](#usage-patterns)
6. [Integration with MindShow](#integration-with-mindshow)
7. [Comparison with Other Libraries](#comparison-with-other-libraries)
8. [Code Examples](#code-examples)
9. [Best Practices](#best-practices)
10. [Implementation Guide](#implementation-guide)

---

## Repository Overview

[MuseLSL2](https://github.com/DominiqueMakowski/MuseLSL2) is a **lightweight, updated reimplementation** of muse-lsl with several key improvements for streaming and recording Muse EEG signals. It's designed to be a modern, reliable interface for Muse headband integration.

### Key Statistics
- **9 stars** - Community recognition
- **2 forks** - Active development interest
- **182 commits** - Active development history
- **MIT license** - Open source and free to use
- **Python 100%** - Pure Python implementation

### Core Advantages
- **Fixed timestamps** - Corrected timestamp accuracy issues
- **mne-lsl integration** - Upgraded LSL interface
- **Complete channel streaming** - All channels including PPG, gyroscope, accelerometer
- **Improved stability** - Fixed timeout and disconnection issues
- **Lightweight** - Minimal dependencies and overhead

---

## Key Improvements

### 1. Fixed Timestamp Correctness
**Problem**: Original muse-lsl had timestamp accuracy issues
**Solution**: MuseLSL2 provides corrected, accurate timestamps for reliable data synchronization

### 2. mne-lsl Integration
**Problem**: Outdated LSL interface
**Solution**: Uses mne-lsl, an upgraded version of the LSL interface with better performance and reliability

### 3. Complete Channel Streaming
**Problem**: Limited channel access
**Solution**: Streams all available channels:
- **EEG channels**: TP9, AF7, AF8, TP10
- **PPG channels**: Heart rate and related data
- **Motion sensors**: Gyroscope, accelerometer
- **Auxiliary port**: AUX channel for additional electrodes

### 4. Enhanced Viewer
**Problem**: Limited visualization capabilities
**Solution**: Viewer shows PPG and related channels in addition to EEG data

### 5. Improved Stability
**Problem**: Timeout and disconnection issues
**Solution**: Fixed timeout handling and improved connection stability

---

## Installation and Setup

### 1. Installation

```bash
# Install from GitHub
pip install https://github.com/DominiqueMakowski/MuseLSL2/zipball/main

# Alternative: Clone and install
git clone https://github.com/DominiqueMakowski/MuseLSL2.git
cd MuseLSL2
pip install -e .
```

### 2. Device Discovery

```bash
# Find available Muse devices
MuseLSL2 find
```

**Output Example**:
```
Found Muse device: 00:55:DA:B5:E8:CF
```

### 3. Streaming Setup

```bash
# Start streaming with device address
MuseLSL2 stream --address 00:55:DA:B5:E8:CF
```

### 4. Visualization

```bash
# View streaming data in real-time
MuseLSL2 view
```

---

## Core Features

### 1. Complete Channel Support

**EEG Channels**:
- TP9 (Temporal-Parietal 9)
- AF7 (Anterior-Frontal 7)
- AF8 (Anterior-Frontal 8)
- TP10 (Temporal-Parietal 10)

**Additional Channels**:
- **PPG**: Heart rate and photoplethysmography data
- **Gyroscope**: 3-axis angular velocity
- **Accelerometer**: 3-axis acceleration
- **AUX**: Auxiliary port for additional electrodes

### 2. Real-Time Streaming

```python
# Stream all channels in real-time
MuseLSL2 stream --address 00:55:DA:B5:E8:CF
```

### 3. Data Recording

```python
# Record streams using Lab Recorder
# Compatible with standard LSL recording tools
```

### 4. Enhanced Viewer

```python
# Real-time visualization of all channels
MuseLSL2 view
```

---

## Usage Patterns

### 1. Basic Streaming

```python
import subprocess
import time

def start_muse_streaming(address):
    """Start Muse streaming with MuseLSL2"""
    try:
        # Start streaming process
        process = subprocess.Popen([
            'MuseLSL2', 'stream', '--address', address
        ])
        
        print(f"Muse streaming started for device: {address}")
        return process
        
    except Exception as e:
        print(f"Failed to start streaming: {e}")
        return None

def stop_muse_streaming(process):
    """Stop Muse streaming"""
    if process:
        process.terminate()
        print("Muse streaming stopped")

# Usage
address = "00:55:DA:B5:E8:CF"
stream_process = start_muse_streaming(address)

try:
    # Keep streaming for 60 seconds
    time.sleep(60)
finally:
    stop_muse_streaming(stream_process)
```

### 2. Device Discovery

```python
import subprocess
import re

def discover_muse_devices():
    """Discover available Muse devices"""
    try:
        # Run device discovery
        result = subprocess.run(['MuseLSL2', 'find'], 
                              capture_output=True, text=True)
        
        # Parse output for device addresses
        output = result.stdout
        devices = re.findall(r'([0-9A-F]{2}:[0-9A-F]{2}:[0-9A-F]{2}:[0-9A-F]{2}:[0-9A-F]{2}:[0-9A-F]{2})', output)
        
        return devices
        
    except Exception as e:
        print(f"Failed to discover devices: {e}")
        return []

# Usage
devices = discover_muse_devices()
print(f"Found {len(devices)} Muse devices: {devices}")
```

### 3. Real-Time Monitoring

```python
import subprocess
import threading
import time

class MuseLSL2Monitor:
    def __init__(self, address):
        self.address = address
        self.stream_process = None
        self.viewer_process = None
        self.running = False
        
    def start_streaming(self):
        """Start Muse streaming"""
        self.stream_process = subprocess.Popen([
            'MuseLSL2', 'stream', '--address', self.address
        ])
        print(f"Started streaming from {self.address}")
        
    def start_viewer(self):
        """Start real-time viewer"""
        self.viewer_process = subprocess.Popen([
            'MuseLSL2', 'view'
        ])
        print("Started real-time viewer")
        
    def start_monitoring(self):
        """Start complete monitoring setup"""
        self.running = True
        
        # Start streaming
        self.start_streaming()
        time.sleep(2)  # Wait for stream to establish
        
        # Start viewer
        self.start_viewer()
        
        try:
            while self.running:
                time.sleep(1)
        except KeyboardInterrupt:
            self.stop_monitoring()
            
    def stop_monitoring(self):
        """Stop all monitoring processes"""
        self.running = False
        
        if self.stream_process:
            self.stream_process.terminate()
            print("Streaming stopped")
            
        if self.viewer_process:
            self.viewer_process.terminate()
            print("Viewer stopped")

# Usage
monitor = MuseLSL2Monitor("00:55:DA:B5:E8:CF")
monitor.start_monitoring()
```

---

## Integration with MindShow

### 1. MuseLSL2 + BrainFlow Integration

```python
import subprocess
import time
import numpy as np
from brainflow.board_shim import BoardShim, BrainFlowInputPresets
from brainflow.data_filter import DataFilter, FilterTypes

class MuseLSL2BrainFlowIntegration:
    def __init__(self, muse_address, pixelblaze_controller):
        self.muse_address = muse_address
        self.pixelblaze = pixelblaze_controller
        self.stream_process = None
        self.brainflow_board = None
        self.running = False
        
    def start_muselsl2_streaming(self):
        """Start MuseLSL2 streaming"""
        self.stream_process = subprocess.Popen([
            'MuseLSL2', 'stream', '--address', self.muse_address
        ])
        print(f"MuseLSL2 streaming started for {self.muse_address}")
        
    def start_brainflow_connection(self):
        """Start BrainFlow connection to receive LSL data"""
        # BrainFlow can receive LSL streams
        self.brainflow_board = BoardShim(
            BrainFlowInputPresets.LSL_BOARD, 
            BrainFlowInputPresets.BLUETOOTH
        )
        self.brainflow_board.prepare_session()
        self.brainflow_board.start_stream()
        print("BrainFlow LSL connection established")
        
    def start_mindshow(self):
        """Start complete MindShow with MuseLSL2 + BrainFlow"""
        self.running = True
        
        # Start MuseLSL2 streaming
        self.start_muselsl2_streaming()
        time.sleep(3)  # Wait for stream to establish
        
        # Start BrainFlow LSL connection
        self.start_brainflow_connection()
        
        try:
            while self.running:
                # Get data from BrainFlow
                data = self.brainflow_board.get_board_data()
                
                if data.shape[1] > 0:
                    # Process EEG data
                    processed_data = self.process_eeg_data(data)
                    
                    # Extract features
                    features = self.extract_features(processed_data)
                    
                    # Calculate biometric scores
                    attention_score = self.calculate_attention_score(features)
                    relaxation_score = self.calculate_relaxation_score(features)
                    
                    # Update Pixelblaze
                    self.update_pixelblaze(attention_score, relaxation_score)
                    
                time.sleep(0.1)  # 10 Hz update rate
                
        except KeyboardInterrupt:
            self.stop_mindshow()
            
    def process_eeg_data(self, data):
        """Process EEG data from BrainFlow"""
        processed_channels = []
        
        for channel_idx in range(min(4, data.shape[0])):  # First 4 channels are EEG
            channel_data = data[channel_idx, -256:]  # Last 256 samples
            
            # Apply filters
            filtered = DataFilter.perform_bandpass(
                channel_data, 256, 1.0, 50.0, 4, FilterTypes.BUTTERWORTH, 0
            )
            
            # Apply notch filter
            notch = DataFilter.perform_notch(
                filtered, 256, 50.0, 4
            )
            
            processed_channels.append(notch)
            
        return np.array(processed_channels)
        
    def extract_features(self, processed_data):
        """Extract features from processed data"""
        features = {}
        channels = ['TP9', 'AF7', 'AF8', 'TP10']
        
        for i, channel in enumerate(channels):
            if i < processed_data.shape[0]:
                # Calculate PSD
                psd = DataFilter.get_psd_welch(
                    processed_data[i], len(processed_data[i]),
                    len(processed_data[i])//2, 256
                )
                
                # Extract band powers
                features[f'{channel}_delta'] = DataFilter.get_band_power(psd, 1.0, 4.0)
                features[f'{channel}_theta'] = DataFilter.get_band_power(psd, 4.0, 8.0)
                features[f'{channel}_alpha'] = DataFilter.get_band_power(psd, 8.0, 13.0)
                features[f'{channel}_beta'] = DataFilter.get_band_power(psd, 13.0, 30.0)
                features[f'{channel}_gamma'] = DataFilter.get_band_power(psd, 30.0, 50.0)
                
        return features
        
    def calculate_attention_score(self, features):
        """Calculate attention score from EEG features"""
        beta_alpha_ratios = []
        
        for channel in ['TP9', 'AF7', 'AF8', 'TP10']:
            beta = features.get(f'{channel}_beta', 0)
            alpha = features.get(f'{channel}_alpha', 1)  # Avoid division by zero
            
            if alpha > 0:
                ratio = beta / alpha
                beta_alpha_ratios.append(ratio)
                
        if beta_alpha_ratios:
            attention_score = np.mean(beta_alpha_ratios)
            return np.clip(attention_score, 0.0, 2.0) / 2.0
        return 0.5
        
    def calculate_relaxation_score(self, features):
        """Calculate relaxation score from EEG features"""
        alpha_theta_ratios = []
        
        for channel in ['TP9', 'AF7', 'AF8', 'TP10']:
            alpha = features.get(f'{channel}_alpha', 0)
            theta = features.get(f'{channel}_theta', 1)  # Avoid division by zero
            
            if theta > 0:
                ratio = alpha / theta
                alpha_theta_ratios.append(ratio)
                
        if alpha_theta_ratios:
            relaxation_score = np.mean(alpha_theta_ratios)
            return np.clip(relaxation_score, 0.0, 2.0) / 2.0
        return 0.5
        
    def update_pixelblaze(self, attention_score, relaxation_score):
        """Update Pixelblaze with biometric data"""
        # Speed control (80%-120% range)
        speed_multiplier = 0.8 + (attention_score * 0.4)
        
        # Color control (ROYGBIV spectrum)
        if attention_score > 0.7:
            base_hue = 0.0  # Red/orange for engaged
        elif relaxation_score > 0.6:
            base_hue = 0.66  # Blue/purple for relaxed
        else:
            base_hue = 0.33  # Green for neutral
            
        # Brightness control
        brightness = 0.5 + (relaxation_score * 0.5)
        
        # Update Pixelblaze
        variables = {
            'speed': speed_multiplier,
            'hue': base_hue,
            'brightness': brightness
        }
        
        try:
            self.pixelblaze.set_variables(variables)
        except Exception as e:
            print(f"Failed to update Pixelblaze: {e}")
            
    def stop_mindshow(self):
        """Stop MindShow"""
        self.running = False
        
        if self.stream_process:
            self.stream_process.terminate()
            print("MuseLSL2 streaming stopped")
            
        if self.brainflow_board:
            self.brainflow_board.stop_stream()
            self.brainflow_board.release_session()
            print("BrainFlow connection closed")

# Usage
pixelblaze = RobustWebSocketController("192.168.0.241")
mindshow = MuseLSL2BrainFlowIntegration("00:55:DA:B5:E8:CF", pixelblaze)
mindshow.start_mindshow()
```

### 2. Direct LSL Integration

```python
import pylsl
import numpy as np
import time

class MuseLSL2DirectIntegration:
    def __init__(self, pixelblaze_controller):
        self.pixelblaze = pixelblaze_controller
        self.running = False
        
    def find_muse_streams(self):
        """Find Muse LSL streams"""
        streams = pylsl.resolve_streams(wait_time=5.0)
        muse_streams = []
        
        for stream in streams:
            if 'Muse' in stream.name() or 'EEG' in stream.name():
                muse_streams.append(stream)
                
        return muse_streams
        
    def start_lsl_receiver(self):
        """Start LSL data receiver"""
        # Find Muse streams
        streams = self.find_muse_streams()
        
        if not streams:
            print("No Muse streams found")
            return None
            
        # Create inlet for first stream
        inlet = pylsl.StreamInlet(streams[0])
        print(f"Connected to stream: {streams[0].name()}")
        
        return inlet
        
    def start_mindshow(self):
        """Start MindShow with direct LSL integration"""
        inlet = self.start_lsl_receiver()
        
        if not inlet:
            return
            
        self.running = True
        
        try:
            while self.running:
                # Get sample from LSL stream
                sample, timestamp = inlet.pull_sample(timeout=0.1)
                
                if sample is not None:
                    # Process EEG data
                    processed_data = self.process_lsl_data(sample)
                    
                    # Extract features
                    features = self.extract_features(processed_data)
                    
                    # Calculate biometric scores
                    attention_score = self.calculate_attention_score(features)
                    relaxation_score = self.calculate_relaxation_score(features)
                    
                    # Update Pixelblaze
                    self.update_pixelblaze(attention_score, relaxation_score)
                    
                time.sleep(0.1)  # 10 Hz update rate
                
        except KeyboardInterrupt:
            self.stop_mindshow()
            
    def process_lsl_data(self, sample):
        """Process LSL sample data"""
        # Convert sample to numpy array
        data = np.array(sample)
        
        # Apply basic filtering (simplified)
        # In production, use more sophisticated filtering
        filtered_data = data * 0.1  # Simple scaling
        
        return filtered_data
        
    def extract_features(self, processed_data):
        """Extract features from processed data"""
        # Simplified feature extraction
        # In production, use FFT and band power calculations
        features = {
            'TP9_alpha': np.mean(processed_data) * 0.1,
            'TP9_beta': np.mean(processed_data) * 0.2,
            'AF7_alpha': np.mean(processed_data) * 0.1,
            'AF7_beta': np.mean(processed_data) * 0.2,
            'AF8_alpha': np.mean(processed_data) * 0.1,
            'AF8_beta': np.mean(processed_data) * 0.2,
            'TP10_alpha': np.mean(processed_data) * 0.1,
            'TP10_beta': np.mean(processed_data) * 0.2,
        }
        
        return features
        
    def calculate_attention_score(self, features):
        """Calculate attention score"""
        beta_values = [features.get(f'{ch}_beta', 0) for ch in ['TP9', 'AF7', 'AF8', 'TP10']]
        alpha_values = [features.get(f'{ch}_alpha', 1) for ch in ['TP9', 'AF7', 'AF8', 'TP10']]
        
        beta_alpha_ratios = []
        for beta, alpha in zip(beta_values, alpha_values):
            if alpha > 0:
                ratio = beta / alpha
                beta_alpha_ratios.append(ratio)
                
        if beta_alpha_ratios:
            attention_score = np.mean(beta_alpha_ratios)
            return np.clip(attention_score, 0.0, 1.0)
        return 0.5
        
    def calculate_relaxation_score(self, features):
        """Calculate relaxation score"""
        alpha_values = [features.get(f'{ch}_alpha', 0) for ch in ['TP9', 'AF7', 'AF8', 'TP10']]
        return np.clip(np.mean(alpha_values), 0.0, 1.0)
        
    def update_pixelblaze(self, attention_score, relaxation_score):
        """Update Pixelblaze with biometric data"""
        # Speed control (80%-120% range)
        speed_multiplier = 0.8 + (attention_score * 0.4)
        
        # Color control (ROYGBIV spectrum)
        if attention_score > 0.7:
            base_hue = 0.0  # Red/orange for engaged
        elif relaxation_score > 0.6:
            base_hue = 0.66  # Blue/purple for relaxed
        else:
            base_hue = 0.33  # Green for neutral
            
        # Brightness control
        brightness = 0.5 + (relaxation_score * 0.5)
        
        # Update Pixelblaze
        variables = {
            'speed': speed_multiplier,
            'hue': base_hue,
            'brightness': brightness
        }
        
        try:
            self.pixelblaze.set_variables(variables)
        except Exception as e:
            print(f"Failed to update Pixelblaze: {e}")
            
    def stop_mindshow(self):
        """Stop MindShow"""
        self.running = False
        print("MindShow stopped")

# Usage
pixelblaze = RobustWebSocketController("192.168.0.241")
mindshow = MuseLSL2DirectIntegration(pixelblaze)
mindshow.start_mindshow()
```

---

## Comparison with Other Libraries

### MuseLSL2 vs BrainFlow

| Feature | MuseLSL2 | BrainFlow |
|---------|----------|-----------|
| **Focus** | Muse-specific | Multi-device |
| **Complexity** | Lightweight | Comprehensive |
| **LSL Integration** | Native | Supported |
| **Installation** | Simple | Complex |
| **Dependencies** | Minimal | Extensive |
| **Real-time Viewer** | Built-in | External tools |
| **Channel Support** | All Muse channels | Device-dependent |

### MuseLSL2 vs Original muse-lsl

| Feature | MuseLSL2 | Original muse-lsl |
|---------|----------|-------------------|
| **Timestamp Accuracy** | ‚úÖ Fixed | ‚ùå Issues |
| **LSL Interface** | ‚úÖ mne-lsl | ‚ùå Outdated |
| **Channel Support** | ‚úÖ Complete | ‚ö†Ô∏è Limited |
| **Stability** | ‚úÖ Improved | ‚ùå Timeout issues |
| **Viewer** | ‚úÖ Enhanced | ‚ö†Ô∏è Basic |
| **Documentation** | ‚úÖ Updated | ‚ùå Outdated |

---

## Code Examples

### 1. Basic MuseLSL2 Usage

```python
import subprocess
import time

def basic_muselsl2_usage():
    """Basic MuseLSL2 usage example"""
    
    # Step 1: Find devices
    print("Discovering Muse devices...")
    result = subprocess.run(['MuseLSL2', 'find'], 
                          capture_output=True, text=True)
    print(result.stdout)
    
    # Step 2: Start streaming (replace with actual address)
    address = "00:55:DA:B5:E8:CF"
    print(f"Starting stream for {address}...")
    
    stream_process = subprocess.Popen([
        'MuseLSL2', 'stream', '--address', address
    ])
    
    # Step 3: Start viewer
    print("Starting viewer...")
    viewer_process = subprocess.Popen(['MuseLSL2', 'view'])
    
    try:
        # Keep running for 30 seconds
        time.sleep(30)
    finally:
        # Cleanup
        stream_process.terminate()
        viewer_process.terminate()
        print("Streaming stopped")

# Run basic usage
basic_muselsl2_usage()
```

### 2. Advanced Integration

```python
import subprocess
import threading
import time
import numpy as np

class AdvancedMuseLSL2Integration:
    def __init__(self, address):
        self.address = address
        self.stream_process = None
        self.viewer_process = None
        self.data_buffer = []
        self.running = False
        
    def start_streaming_with_monitoring(self):
        """Start streaming with data monitoring"""
        self.running = True
        
        # Start streaming
        self.stream_process = subprocess.Popen([
            'MuseLSL2', 'stream', '--address', self.address
        ])
        
        # Start viewer in separate thread
        viewer_thread = threading.Thread(target=self._start_viewer)
        viewer_thread.daemon = True
        viewer_thread.start()
        
        # Monitor data
        self._monitor_data()
        
    def _start_viewer(self):
        """Start viewer in separate thread"""
        self.viewer_process = subprocess.Popen(['MuseLSL2', 'view'])
        
    def _monitor_data(self):
        """Monitor streaming data"""
        start_time = time.time()
        
        while self.running:
            # Simulate data monitoring
            elapsed = time.time() - start_time
            print(f"Streaming for {elapsed:.1f} seconds...")
            
            # Check if process is still running
            if self.stream_process and self.stream_process.poll() is not None:
                print("Streaming process stopped unexpectedly")
                break
                
            time.sleep(5)  # Check every 5 seconds
            
    def stop_streaming(self):
        """Stop all streaming processes"""
        self.running = False
        
        if self.stream_process:
            self.stream_process.terminate()
            print("Streaming stopped")
            
        if self.viewer_process:
            self.viewer_process.terminate()
            print("Viewer stopped")

# Usage
integration = AdvancedMuseLSL2Integration("00:55:DA:B5:E8:CF")
integration.start_streaming_with_monitoring()
```

### 3. Data Recording Integration

```python
import subprocess
import time
import os

class MuseLSL2Recorder:
    def __init__(self, address, output_dir="recordings"):
        self.address = address
        self.output_dir = output_dir
        self.stream_process = None
        self.recording_process = None
        
        # Create output directory
        os.makedirs(output_dir, exist_ok=True)
        
    def start_recording(self, duration=60):
        """Start recording Muse data"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"muse_recording_{timestamp}.xdf"
        filepath = os.path.join(self.output_dir, filename)
        
        # Start streaming
        self.stream_process = subprocess.Popen([
            'MuseLSL2', 'stream', '--address', self.address
        ])
        
        print(f"Started streaming for recording: {filepath}")
        
        # Wait for stream to establish
        time.sleep(3)
        
        # Start Lab Recorder (if available)
        try:
            self.recording_process = subprocess.Popen([
                'LabRecorder', '--filename', filepath
            ])
            print(f"Started recording to: {filepath}")
        except FileNotFoundError:
            print("LabRecorder not found. Using manual recording.")
            
        # Record for specified duration
        time.sleep(duration)
        
        # Stop recording
        self.stop_recording()
        
    def stop_recording(self):
        """Stop recording"""
        if self.stream_process:
            self.stream_process.terminate()
            print("Streaming stopped")
            
        if self.recording_process:
            self.recording_process.terminate()
            print("Recording stopped")

# Usage
recorder = MuseLSL2Recorder("00:55:DA:B5:E8:CF")
recorder.start_recording(duration=120)  # Record for 2 minutes
```

---

## Best Practices

### 1. Error Handling

```python
import subprocess
import time

def robust_muselsl2_streaming(address):
    """Robust MuseLSL2 streaming with error handling"""
    try:
        # Check if device is available
        result = subprocess.run(['MuseLSL2', 'find'], 
                              capture_output=True, text=True)
        
        if address not in result.stdout:
            raise ValueError(f"Device {address} not found")
            
        # Start streaming
        process = subprocess.Popen([
            'MuseLSL2', 'stream', '--address', address
        ])
        
        # Wait for process to start
        time.sleep(2)
        
        if process.poll() is not None:
            raise RuntimeError("Streaming process failed to start")
            
        return process
        
    except Exception as e:
        print(f"Failed to start streaming: {e}")
        return None
```

### 2. Connection Management

```python
class MuseLSL2ConnectionManager:
    def __init__(self, address):
        self.address = address
        self.process = None
        self.connected = False
        
    def connect(self):
        """Establish connection"""
        try:
            self.process = subprocess.Popen([
                'MuseLSL2', 'stream', '--address', self.address
            ])
            
            # Wait for connection
            time.sleep(3)
            
            if self.process.poll() is None:
                self.connected = True
                print(f"Connected to {self.address}")
                return True
            else:
                print("Connection failed")
                return False
                
        except Exception as e:
            print(f"Connection error: {e}")
            return False
            
    def disconnect(self):
        """Disconnect"""
        if self.process:
            self.process.terminate()
            self.connected = False
            print("Disconnected")
            
    def is_connected(self):
        """Check connection status"""
        if self.process:
            return self.process.poll() is None
        return False
```

### 3. Data Validation

```python
def validate_muselsl2_data(data):
    """Validate MuseLSL2 data quality"""
    if data is None:
        return False, "No data received"
        
    # Check for expected channels
    expected_channels = 4  # TP9, AF7, AF8, TP10
    if len(data) < expected_channels:
        return False, f"Insufficient channels: {len(data)} < {expected_channels}"
        
    # Check for valid values
    for channel_data in data:
        if np.any(np.isnan(channel_data)):
            return False, "Data contains NaN values"
            
        if np.any(np.isinf(channel_data)):
            return False, "Data contains infinite values"
            
    return True, "Data validation passed"
```

---

## Implementation Guide

### 1. Setup Phase

**Step 1: Install MuseLSL2**
```bash
pip install https://github.com/DominiqueMakowski/MuseLSL2/zipball/main
```

**Step 2: Discover Devices**
```bash
MuseLSL2 find
```

**Step 3: Test Streaming**
```bash
MuseLSL2 stream --address YOUR_DEVICE_ADDRESS
```

### 2. Integration Phase

**Step 1: Basic Integration**
```python
# Start MuseLSL2 streaming
# Connect BrainFlow to LSL stream
# Process EEG data
# Update Pixelblaze
```

**Step 2: Advanced Integration**
```python
# Add error handling
# Implement data validation
# Add performance monitoring
# Deploy production system
```

### 3. Production Phase

**Step 1: Monitoring**
```python
# Monitor connection stability
# Track data quality
# Log performance metrics
```

**Step 2: Optimization**
```python
# Optimize update rates
# Minimize latency
# Improve reliability
```

---

## Conclusion

[MuseLSL2](https://github.com/DominiqueMakowski/MuseLSL2) provides a **lightweight, reliable alternative** to more complex EEG libraries. Key takeaways for MindShow:

### **üéØ Core Advantages**
- **Lightweight** - Minimal dependencies and overhead
- **Muse-specific** - Optimized for Muse headband
- **Fixed issues** - Corrected timestamp and stability problems
- **Complete channels** - All Muse channels including PPG and motion
- **Easy integration** - Simple installation and usage

### **‚ö° Integration Benefits**
- **Simple setup** - Easy installation and device discovery
- **Real-time viewer** - Built-in visualization
- **LSL compatibility** - Works with BrainFlow and other tools
- **Stable streaming** - Fixed timeout and disconnection issues

### **üöÄ MindShow Integration**
- **Direct LSL integration** - Connect to BrainFlow for processing
- **Complete data access** - All Muse channels available
- **Reliable streaming** - Stable connection for production use
- **Easy deployment** - Simple setup for end users

### **üìã Implementation Strategy**
1. **Install MuseLSL2** - Simple pip installation
2. **Test with Muse** - Use existing Muse headband
3. **Integrate with BrainFlow** - Connect LSL streams
4. **Deploy to production** - Reliable, lightweight solution

**MuseLSL2 provides a lightweight, reliable foundation for Muse integration that complements our existing BrainFlow and Pixelblaze research!** üéâ

---

*Document generated from analysis of [DominiqueMakowski/MuseLSL2](https://github.com/DominiqueMakowski/MuseLSL2) repository* 